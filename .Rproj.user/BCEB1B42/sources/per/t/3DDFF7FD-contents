# Getting Started with Data {#sec-getting-started}

Data is everywhere. Yet many of us find numbers intimidating. When people make claims using numbers, they often appear authoritative. It's tempting to assume that if someone is sophisticated enough to fluently cite numerical information, they must be worth taking seriously. At the same time, there is a kind of backlash to using numbers to describe the world. The title of the popular book *How to Lie with Statistics* captures a cynicism many people feel: since statistics can easily trick you, you shouldn't believe them at all. Such extreme reactions reflect people's lack of self-confidence in evaluating quantitative information. Because we don't trust ourselves, we reflexively either dismiss or accept numerical claims—perhaps depending on whether the claim is one we already agree with or the source is one we trust.

Fortunately, understanding of statistics is something that most anyone can learn. Even if you think you are not a "numbers person," I am confident that you can learn important fundamentals of statistics that will allow you to critically assess statistical claims for yourself. I say this because I have spent much of my academic life surrounded by people who lacked confidence in their numerical abilities and yet decided to study public affairs—sometimes not realizing the extent to which they were signing up to work with numbers along the way. Many peers during my time studying for a PhD thought their abilities in math were not strong, but by the time they completed their degrees, they were all exceptionally competent in statistics. In my experience, it is true that some people learn numerical concepts quicker than others. For most people, lots of repetition is required before many statistical concepts are fully grasped. But I have yet to encounter a student who is unable to learn the fundaments of statistics. If you set your mind to it, you will learn statistics.

In my opinion, the most important part of evaluating or conducting statistical analyses is critical thinking. While modern-day statistics is highly quantitative, doing statistical analysis typically does not require you to perform any complex mathematical operations because statistical software will handle the number crunching. Thus, being comfortable with statistics is mostly about developing familiarity with abstract statistical concepts and thinking carefully about how to best apply statistical tools to real-world data. Sometimes, a bit of math will be helpful for explaining how a statistic works or understanding the implications of a statistical result. But even then, most of the math we need for an introductory course is relatively simple arithmetic.

## 3 Questions to Always Ask about Data

To help focus your attention on thinking critically, I encourage you to ask the following three questions whenever you encounter statistical information:

1.  What is being measured?

2.  Who (or what) is in the dataset?

3.  How big are the differences?

::: callout-tip
## Long-Term Trends in U.S. Education  {.unnumbered}

Many have argued that despite huge investments in public schooling (at the primary and secondary level), we have little to show in terms of learning gains.

\[figure showing 17-y.o. naep trend + spending trend\]

Notice that there are two y-axes on this graph, displaying different units. That is because the trend in Math learning skills is superimposed over the trend in spending levels, despite the fact that these two variables are measured in entirely different units. In my experience, the use of two separate y-axes often corresponds to poor data visualization and the potential to confuse readers, although I would not go so far as to say that one should never use two y-axes. Nonetheless, it should be cause for pause.

In this case, I will mostly ignore the spending trend in favor of evaluating the Math trend. But I will briefly note that increased spending is largely driven by (1) increasing (high-skilled) labor costs across the economy and (2) greater investments in special education—investments that likely improve equity and fairness in society but may do little to improve test scores.

Regarding the math trend, let us consider the 3 Questions:

1.  What is being measured? If you were encountering this data for the first time, I would recommend doing a Google or Wikipedia search for NAEP scores, perhaps reading some of the description on Wikipedia or the NCES website. You would find that these are results from standardized tests conducted by the U.S. Department of Education. If you wanted to go even deeper, you might do a Google Scholar search to see how researchers seem to be discussing/using NAEP scores. They are generally considered to be high-quality measures of student learning.

2.  Who is in the dataset? If you did some basic reading about the NAEP as suggested for the prior question, you would probably find that NAEP scores are available for grades 4, 8, and 12. Yet the graph only depicts grade 12. On the on hand, it might seem that the final grade is the most important since it indicates how students are doing at the end of their secondary education. On the other hand, it might be useful to see what the other trends look like. Again, a quick Google search for "naep scores over time" will likely return a government website showing naep scores for lower grade levels, with a clear upward trend:

    \[figure here: <https://www.nationsreportcard.gov/ltt>\]

    From this digging, you might conclude that there was perhaps some cherry picking in presenting the initial graph, since the trend at the 12th grade level shows markedly less improvement than the trends at the 4th and 8th grade levels. And that might be all you could reasonably conclude if you have not spent a lot of time studying U.S. education policy. That is an important conclusion to reach and helps you put the original graph in context.

    If you do have some expertise in U.S. education, you might realize that one potentially relevant difference between 8th grade and 12th grade in the U.S. is that school attendance is typically compulsory at 8th grade but not at 12th grade. And a quick Google search (e.g., "change in school dropout rate over time") will reveal government reports showing that the dropout rate has declined markedly on some measures. Thus, one potential explanation for the flat trendline in 12th grade NAEP scores is that in prior decades the 12th grade scores were artificially inflated due to lower-performing students dropping out of high school and thus not taking the exams. In more recent years, more of these lower-performing student remain in school (a positive policy outcome) and even if they are learning more than in the past, their continue presence in schools brings the average NAEP average down compared to the past—leading to flat overall scores even if comparable students are doing better than in the past. \[need citation\]

3.  sdf
:::

We will return to some of these three questions later on in the chapter.

## How Datasets are Structured

We typically display data in the form of a spreadsheet. In the table below, we see a small dataset describing a few countries. Each row represents one country, and we call the rows **observations**. Each column represents one characteristic of the countries. We call the columns **variables**. Variables allow us to describe whatever it is we care about—concepts like country wealth, average education level, amount of government spending on social programs, or civil service culture. We call them ***vari***ables because the value of the characteristic will ***vary*** depending on which observation we are talking about: xxx has a gross domestic product of \_\_\_\_ while ….

\[table of cross-national data\]

The next table shows a dataset where each observation (row) is a different individual who responded to a survey. We use the term **unit of analysis** to describe what constitutes one observation in a dataset: in the prior table the unit of analysis was the country, whereas here it is the individual. Other common units of analysis are the organization, the work unit, and the subnational unit (e.g., county or region).

\[table of survey data\]

### Types of variables

We also distinguish among different kinds of variables, which will often require different types of analysis.

**Quantitative variables** are typically expressed in numbers. …

For **qualitative variables**, it typically makes more sense to use text instead of numbers to describe the values. For example… While you may sometimes encounter datasets that record the values of a qualitative variable using numbers (for ease of processing), the assignment of numbers to values will be arbitrary. This is because qualitative variables take on values that are unordered categories (cannot be arranged from least to most).

A qualitative variable that takes on only two values is also called a **binary variable**. Binary variables often appear in spreadsheets with values shown as 1s and 0s. In some cases, a 1 roughly indicates “yes” while a 0 indicates “no.” For example, in the spreadsheet above the variable “former_british_colony” is coded as a 1 if “yes, this country is a former British colony” and 0 if it is not. 

There is also a third type of variable called an **ordinal variable**, where values can be arranged in order but cannot be easily quantified. This type exists in a somewhat grey zone between quantitative and qualitative. Many surveys utilize Likert scales, which allow respondents to choose from a range of options along a continuum (e.g., strongly disagree, somewhat disagree, somewhat agree, strongly agree). This response format results in an original variable: while we can arrange response options on our Likert scale from most agreement to least agreement, it is not clear how to assign precise numbers because we don’t know if the distances between response options are equal. If “strongly disagree” is a 1 and “somewhat disagree” is a 2, should “somewhat agree” be a 3? Or a 4? Maybe 3.5? It is difficult to say what numbering scheme would most accurately represent respondents’ attitudes because this is an ordinal variable.

\[probably can delete:\] When it comes to analysis, we usually start by discussing methods for quantitative and for qualitative variables. What about ordinal ones? As we will soon see, we often have the option of treating ordinal variables as either quantitative or qualitative. Some techniques have also been developed specifically for handling ordinal variables, although these techniques are generally beyond the scope of what is covered in this text.

### Types of datasets

So far, the datasets we have seen are what we call **cross sections**. Each observation is a different unit. There are also **time series** datasets, where each observation is a different point in time. For example, we see in the following table yearly data on government spending. With time series data, the unit of analysis could be the year (as in the table below), the quarter, the month, the week, the day, etc.

\[table of time series data\]

You may also sometimes encounter more complicated data structures that combine the attributes of cross-sectional and time series data. A **panel** dataset tracks multiple units over multiple time periods. For example, a dataset might track several countries over several years (each row describing one country in one year). A **repeated cross-section** is similar, except that different units are observed in each time period. A survey that is conducted annually but where the respondents are different each year is a repeated cross section.

### Varying terminology

Unfortunately, there are many cases where statistical terminology is inconsistent from one source to the next. Since you will probably encounter research reports or articles that use different terminology than I use here, it is important to be familiar with these alternative terms:

-   Qualitative variables can also be called **categorical variables** or **nominal variables**.

-   Binary variables are often called **dummy variables**.

-   Time series data is sometimes called **longitudinal data**.

Sources also disagree on whether ordinal variables should be considered a subcategory of quantitative or qualitative variables. For this text, I consider ordinal variables to be their own distinct third category, but different authors classify them somewhat differently.

## Visualization Basics

qualitative: bar charts (also works well for ordinal), pie charts (less common in scientific papers)

quant: histograms (explain in detail), then briefly explain k-density plots, violin plots, strip plots, boxplots - line graphs for time series data - other types of bar charts

\[skip detailed explanation of bloxplots for now b/c they require percentiles; come back to them in Ch. 2\]

## Critically Evaluating Graphs

Graphs are often poorly constructed in ways that can mislead. Let's look at some examples and try using the 3 Questions to Always Ask about Data to see if we can identify misleading graphs.

-   show how differences/steepness can always be made to looks as flat, steep as you want
-   maybe show how different vaccine trend looks if including 0 on % vaccinated vs % unvaccinated
